%% Adaptado de 
%% http://www.ctan.org/tex-archive/macros/latex/contrib/IEEEtran/
%% Traduzido para o congresso de IC da USP
%%*****************************************************************************
% Não modificar

\documentclass[twoside,conference,a4paper]{IEEEtran}

%******************************************************************************
% Não modificar
\usepackage{IEEEtsup} % Definições complementares e modificações.
\usepackage[latin1]{inputenc} % Disponibiliza acentos.
\usepackage[english,brazil]{babel}
%% Disponibiliza Inglês e Português do Brasil.
\usepackage{latexsym,amsfonts,amssymb} % Disponibiliza fontes adicionais.
\usepackage{theorem} 
\usepackage[cmex10]{amsmath} % Pacote matemático básico 
\usepackage{url} 
%\usepackage[portuges,brazil,english]{babel}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{color}
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}
\usepackage[tight,footnotesize]{subfigure} 
\usepackage[noadjust]{cite} % Disponibiliza melhorias em citações.
%%*****************************************************************************

\begin{document}
\selectlanguage{brazil}
\renewcommand{\IEEEkeywordsname}{Palavras-chave}

%%*****************************************************************************

\urlstyle{tt}
% Indicar o nome do autor e o curso/nível (grad-mestrado-doutorado-especial)
\title{%
	Aprendizado por Demonstração \\
	\large Levantamento Bibliográfico \\
}

\author{%
 \IEEEauthorblockN{Luísa Madeira Cardoso\,\IEEEauthorrefmark{1}}
 \IEEEauthorblockA{\IEEEauthorrefmark{1}%
                   Aluno especial - Mestrado \\
                   E-mail: lu.madeira2@gmail.com}
}

%%*****************************************************************************

\maketitle

%%*****************************************************************************
% Resumo do trabalho
\begin{abstract}
Este artigo é um levantamento bibliográfico sobre Aprendizado por Demonstração. O tópico vem sendo explorado há décadas por pesquisadores na área de robótica. Poderia um robô aprender uma tarefa dada uma demonstração da mesma? O tema evoluiu deste a simples reprodução de um comportamento gravado para técnicas complexas de derivação de comportamentos genéricos baseadas em Aprendizado de Máquina. 
\end{abstract}

% Indique três palavras-chave que descrevem o trabalho
\begin{IEEEkeywords}
Aprendizado por Demonstração, Learning from demonstration, Imitation Learning, Programming by Demonstration, Aprendizado por Reforço
\end{IEEEkeywords}

%%*****************************************************************************
% Modifique as seções de acordo com o seu projeto

\section{Introdução}
O aprendizado por demonstração vem sendo um dos tópicos mais pesquisados na robótica durante os últimos 30 anos. A ideia do conceito é simples: seria possível treinar um robô para executar uma determinada tarefa demonstrando como ela pode ser executada? 

Técnicas de aprendizado baseadas em demonstração são referenciadas por uma série de termos na literatura, como: "Imitation learning", "Programming by Demonstration (PbD)", "Assembly Plan from Observation", "Learning by Showing", "Learning
by Watching" e "Learning from Observation". Neste levantamento a categoria será denotada pelo termo "Learning from Demonstration" (LfD), conforme sugerido por Argall et al \cite{argall2009survey}.

A relevância do tópico é grande especialmente levando em consideração o Aprendizado por Reforço\cite{kober2013reinforcement}. Isto porque o processo de aprendizado por reforço demanda uma exploração de novos estados e ações. O universo de busca geralmente é considerado infinito e contém diversos elementos que não são importantes para o resultado esperado. Portanto, qualquer técnica que auxilie nesta exploração é interessante. É nesse sentido que o LfD se mostra extremamente útil: ele é um ponto de partida para o sistema e reduz drasticamente o número de estados que precisa ser visitado para encontrar uma solução viável. 

Este artigo apresenta um levantamento bibliográfico sobre o assunto. A primeira seção apresenta uma visão histórica do tema. A seção 2 apresenta uma definição geral do problema. A seção 3 apresenta as principais técnicas de coleta de exemplos que existem na literatura. A seção 4 foca nos métodos de derivação de políticas a partir dos dados coletados. A seção 5 cita brevemente problemas abertos na área. 


\section{História}

No início da década de 80, impulsionado pelo interesse da indústria, as primeiras abordagens de técnicas baseadas em demonstração começaram a surgir\cite{billard2008robot}. O objetivo era substituir a programação manual de uma tarefa a ser executada por um robô por um meio automático de aprendizagem. Isso reduziria custos de desenvolvimento e manutenção do mesmo.

As primeiras abordagens para o "\textit{Programming by Demonstration (PbD)}" utilizavam técnicas de raciocínio simbólico. A demonstração era realizada através da tele-operação num processo chamado \textit{"guiding"} \cite{lozano1983robot}. O robô gravava as ações primitivas executadas e as posições dos objetos manipulados. Posteriormente, a tarefa poderia ser re-executada (\textit{"played-back"}). Esta abordagem apresentava uma série de problemas, uma simples variação na posição do objeto manipulado, por exemplo, representava uma falha porque o estado não era esperado.  

Em 1994 Muench \cite{muench1994robot} propôs a utilização de técnicas de aprendizado de máquina para auxiliar no \textit{PbD}. A meta era aprimorar o aprendizado que simplesmente era capaz de repetir os movimentos aprendidos, empregando soluções que realmente envolviam \textit{aprendizado}. Para alcançar este objetivo dois problemas precisavam ser solucionados: (1)  o modelo de representação da demonstração; (2) prover um número suficiente de exemplos para obter uma modelagem genérica. A partir deste momento o termo "Learning from Demonstration (LfD)" ser tornou mais apropriado para referenciar o assunto. 

A área evoluiu os mecanismos de captação do aprendizado como a utilização de técnicas de visão computacional, \textit{werables} e \textit{kinesthetic
teaching} (manualmente guiar o braço robótico para lhe realizar a demonstração do movimento)\cite{calinon2007learning}.
Além disso, o LfD passou a incorporar avanços na área de Aprendizado de Máquina, tanto para questão de percepção quanto para generalização do modelo aprendido, empregando técnicas como lógica \textit{Fuzzy}, \textit{Artificial Neural Networks}, \textit{Radial-Basis Function Networks} e  \textit{Hidden Markov Models}.

Nos últimos 15 anos com o progresso do esforço interdisciplinar entre robótica e biologia, a área de LfD passou a levar em consideração 
evidência de mecanismos neurais específicos para imitação visual encontrada em primatas \cite{schaal1999imitation}. O termo mais biológico  \textit{"Imitation Learning"} surgiu nesse cenário. 


\section{Definição}

O Aprendizado por Demonstração é um ramo do Aprendizado Supervisionado. 
De modo geral, é uma técnica para assimilação de políticas através da observação de exemplos ou demonstrações. Neste contexto, um exemplo é uma sequência de pares de estado-ação e uma política pode ser entendida como a lógica para transitar entre estes pares. Esta abordagem difere de técnicas de aprendizado por \textit{experiência}, tais como o Aprendizado por Reforço. Através da execução provida por um instrutor, o agente armazena os estados e as ações selecionadas. A política é então derivada destas entradas através de uma função específica, podendo ser inclusive um mapeamento exato do comportamento do demonstrador. 


\section{Coletando exemplos}
O conjunto de dados utilizados pelo LfD é composto de pares estado-ação que foram de alguma forma obtidos durante a demonstração. Esses pares precisam necessariamente ter a capacidade de serem utilizados diretamente pelo robô. Porém, na prática um mapeamento direto dos exemplos de entrada nem sempre é possível, visto que podem haver cenários nos quais o executor da demonstração nem sempre é o aluno. 

O demonstrador pode ser é quem executa a ação que irá ser aprendida. A escolha deste também pode ser quebrada em outras duas categorias: quem controla a ação e quem executa a demonstração. Geralmente os demonstradores são humanos, mas também existem estudos que utilizam outros robôs ou simuladores no papel de instrutores. 

As técnicas para realizar uma demonstração podem ser dividas em duas grandes categorias:
\begin{itemize}
\item Tele-operação: o instrutor opera o robô e este grava a execução. O professor pode tanto controlar o robô remotamente, quanto aplicar o \textit{kinesthetic teaching} ( o robô passivamente é controlado por um humano que mexe suas juntas).
\item \textit{Shadowing}: O robô registra a execução usando seus próprios sensores
e tenta imitar os movimentos do professor.
\item Sensores no professor: técnica de imitação na qual os sensores estão localizados no corpo do professor. Um exemplo é a utilização de luvas que capturam o movimento de uma mão.
\item Observação Externa: técnica de imitação na qual os sensores são externos ao corpo do professor e podem ou não pertencer ao aprendiz. A utilização de visão computacional é um exemplo  desta categoria. 
\end{itemize}

\begin{figure}[ht]
\centering
\includegraphics[width=1\hsize]{images/ball-in-a-cup.png}
\caption{Exemplo de \textit{kinesthetic teaching} \cite{nemec2010learning}}
\label{fig:policy-tech}
\end{figure}


\section{Derivando uma política}

Após o passo de coletar exemplos é necessário derivar uma política, realizando assim o aprendizado. As três principais técnicas para realizar essa tarefa estão descritas a seguir e sumarizadas na figura \ref{fig:policy-tech}.
\begin{itemize}
\item Mapeamento de funções: os dados de demonstração são usados para mapear diretamente um par estado-ação.  
\item Modelo sistemático: os dados de demonstração são utilizados para determinar um modelo de dinâmicas e possivelmente uma função de recompensa. A formulação do sistema se dá geralmente em termos de Aprendizado por Reforço. 
\item Planos: os dados de demonstração são utilizados para aprender regras que associam pré e pós condições a cada ação. Uma plano de ações é então derivado destas observações. 
\end{itemize}

\begin{figure}[ht]
\centering
\includegraphics[width=1\hsize]{images/policy.png}
\caption{As três principais técnicas de derivação de políticas. Extraído de Argal et al \cite{argall2009survey}}
\label{fig:policy-tech}
\end{figure}

Três subcategorias da classificação apresentada serão descritas a seguir. 

\subsection{Mapeamento: Classificação}
Técnicas de classificação por definição mapeiam o conjunto de entrada em classes discretas. No contexto de derivação de políticas para o LfD, as entradas são compostas pelos estados do agente, enquanto as ações são discretizadas em categorias e compõe a saída do sistema. Assim, métodos como \textit{Decision Trees}\cite{sammut2014learning}, \textit{Gaussian Mixture Models} \cite{chernova2007confidence}, \textit{Bayesian networks} \cite{inoue1999acquisition} podem ser utilizados. 

\subsection{Mapeamento: Regressão}
Semelhante à classificação, a entrada para o regressor são os estados do robô. Porém a saída deixa de ser discreta e passa a ser contínua, representando de alguma forma uma ação. Exemplos de sua utilização são a aplicação de Redes Neurais para possibilitar direção autônoma de veículos \cite{pomerleau1991efficient}. 


\subsection{Modelo sistemático: funções de recompensa programadas}
Este método utiliza técnicas de aprendizado por reforço nas quais as funções de recompensa são definidas pelo programador. Neste contexto, a demonstração vem sendo utilizada para auxiliar o robô em localizar as recompensas diminuindo o espaço de busca. 

\section{Tópicos abertos}

Os tópicos abertos na área de Aprendizado por Demonstração segundo Billard \cite{billard2008robot} são:
\begin{itemize}
\item Como a imitação pode contribuir para o aprendizado motor?
\item A imitação pode acelerar o aprendizado de habilidades?
\item É possível encontrar um modelo de representação de movimento que seja comum ao reconhecimento de gestos e o controle motor?
\item Como extrair a intenção de uma ação apenas por observar sua demonstração?
\item Como criar uma combinação de Aprendizado por Demonstração com Aprendizado por Reforço de modo que o sistema aprenda em menos tentativas?
\end{itemize}

\section{Conclusão}
O Aprendizado por Demonstração vem contribuindo para importantes avanços na robótica, especialmente no âmbito do desenvolvimento de comportamentos mais robustos e inteligentes. Além disso, as técnicas de LfD representam uma forma mais intuitiva e natural de comunicação com o robô. Pode-se perceber que a abordagem vem sendo extensivamente utilizada para auxiliar no Aprendizado por Reforço de tarefas.  


%******************************************************************************
% Referências - Definidas no arquivo Relatorio.bib
 +-------------+

\bibliographystyle{IEEEtran}

\bibliography{Relatorio}


%******************************************************************************

\end{document}
